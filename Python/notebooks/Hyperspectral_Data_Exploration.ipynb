{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f04ccc0",
   "metadata": {},
   "source": [
    "# An Introduction to Hyperspectral Imaging with CUVIS SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf8f56-fa58-41df-9b3c-32489901dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # File system operation\n",
    "import numpy as np # Load numeric data operations\n",
    "import cuvis # Load the Cubert SDK\n",
    "import traceback # Debugging errors\n",
    "import typing # Typehints for python data\n",
    "from IPython.display import display, clear_output # Interactive tools for Notebooks\n",
    "from tqdm import tqdm # Interactive progress bar\n",
    "import ipywidgets as widgets\n",
    "import traitlets\n",
    "from ipyfilechooser import FileChooser\n",
    "import cv2 # OpenCV proxy library\n",
    "from sklearn.decomposition import PCA # Data dimensionality reduction\n",
    "import matplotlib.pyplot as plt # Visualization of images\n",
    "import cuvis.classificator as cuvClass # Beta Classification Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c20de7",
   "metadata": {},
   "source": [
    "### Select and Image to Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d279e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lib_dir = os.getenv(\"CUVIS\")\n",
    "default_path = os.path.normpath(os.path.join(lib_dir, os.path.pardir, \"sdk\", \"sample_data\", \"set1\"))\n",
    "fc = FileChooser(default_path)\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96f396",
   "metadata": {},
   "source": [
    "### Load the sample data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8191708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a Measurement from the Image\n",
    "try:\n",
    "    mesu = cuvis.Measurement(fc.selected)\n",
    "except Exception as e:\n",
    "    print(traceback.print_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6104f8",
   "metadata": {},
   "source": [
    "### Explore the Metadata on the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e848633-bde7-4211-b29f-75cecdcd625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyprint_attributes(mesu: cuvis.Measurement) -> None:\n",
    "    for attribute in dir(mesu):\n",
    "        if type(getattr(mesu, attribute)).__name__ not in ['builtin_function_or_method', 'method'] and '__' not in attribute:\n",
    "            print(f'{attribute}:\\t{getattr(mesu, attribute)}')\n",
    "\n",
    "# Let's examine our measurement\n",
    "prettyprint_attributes(mesu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad6f376",
   "metadata": {},
   "source": [
    "### Now let's look at the actual data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd915678",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mesu.Data[\"cube\"].array\n",
    "# Let's look at the shape of the hypercube\n",
    "print(f'Rows: {data.shape[0]}, Columns: {data.shape[1]}, Bands: {data.shape[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5395693d",
   "metadata": {},
   "source": [
    "Hyperspectral data from Cubert is read into a 3 dimensional structure. Each images, has a width, height, and band dimension. You can access specific points of this data by using numeric python operations using the popular `numpy` library. If our hypercube is called `data` we can perform some operations to find specific portions\n",
    "```\n",
    "data[:,:,0] # Select the first band in the cube\n",
    "data[0,0,:] # Select the spectral profile for a specific pixel\n",
    "data[10:20,10:20,:] # Select a square region of interest (ROI) using array slicing\n",
    "```\n",
    "To read more about all the things you can do with array silicing to select, and downsample datacubes, please read the [official numpy documentation](https://numpy.org/doc/stable/user/basics.indexing.html).\n",
    "\n",
    "Below let's extract the first wavelength channel and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e208933",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f2fd73",
   "metadata": {},
   "source": [
    "### Visualizaiton with IPyWidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38751e29",
   "metadata": {},
   "source": [
    "Jupyter Notebooks are also great for building interactive tools for data analysis. In the cell below, we have constructed a simple graphical user interface to explore hyperspectral data. This leverages the [IPyWidgets](https://ipywidgets.readthedocs.io/en/stable/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9671e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "out = widgets.Output()\n",
    "out_spectra = widgets.Output()\n",
    "slider = widgets.SelectionSlider(\n",
    "    options=mesu.Data[\"cube\"].wavelength,\n",
    "    value=mesu.Data[\"cube\"].wavelength[0],\n",
    "    description='Channel:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True\n",
    ")\n",
    "x_val = widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=data.shape[0]-1,\n",
    "    step=1,\n",
    "    description='X Coord:',\n",
    "    disabled=False\n",
    ")\n",
    "y_val = widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=data.shape[1]-1,\n",
    "    step=1,\n",
    "    description='Y Coord:',\n",
    "    disabled=False\n",
    ")\n",
    "neighborhood = widgets.BoundedIntText(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Avg. Radius',\n",
    "    disabled=False\n",
    ")   \n",
    "# Create initial bytes\n",
    "def on_value_change(change):\n",
    "    # Update the visualization\n",
    "    if 'Channel' in change['owner'].description and isinstance(change['new'], int) and change['new'] in mesu.Data[\"cube\"].wavelength:\n",
    "        new_channel = change['new']\n",
    "        show_channel(new_channel)\n",
    "    elif 'X Coord' in change['owner'].description and isinstance(change['new'], int):\n",
    "        plot_spectra()\n",
    "        show_channel(slider.value)\n",
    "    elif 'Y Coord' in change['owner'].description and isinstance(change['new'], int):\n",
    "        plot_spectra()\n",
    "        show_channel(slider.value)\n",
    "    elif 'Avg. Radius' in change['owner'].description and isinstance(change['new'], int):\n",
    "        plot_spectra()\n",
    "        show_channel(slider.value)\n",
    "\n",
    "def show_channel(new_channel: int) -> None:\n",
    "    x = x_val.value\n",
    "    y = y_val.value\n",
    "    with out:\n",
    "        clear_output(True)\n",
    "        new_channel = mesu.Data[\"cube\"].wavelength.index(new_channel)\n",
    "        plt.imshow(data[:,:,new_channel], cmap='gray', extent=[0, data.shape[1], 0, data.shape[0]])\n",
    "        plt.plot([x], [y], marker=\"o\", markersize=neighborhood.value+2, markeredgecolor=\"red\", markerfacecolor=\"green\")\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.show()\n",
    "        \n",
    "def average_spectra(radius: int) -> np.array:\n",
    "    x = x_val.value\n",
    "    y = y_val.value\n",
    "    min_x = x-radius if x-radius > 0 else 0\n",
    "    min_y = y-radius if y-radius > 0 else 0\n",
    "    sample = data[min_x:x+radius,min_y:y+radius,:]\n",
    "    sample = sample.reshape(sample.shape[0]*sample.shape[1],sample.shape[2])\n",
    "    return np.mean(sample,axis=0)\n",
    "            \n",
    "def plot_spectra() -> None:\n",
    "    x = x_val.value\n",
    "    y = y_val.value\n",
    "    with out_spectra:\n",
    "        clear_output(True)\n",
    "        sample = average_spectra(neighborhood.value)\n",
    "        plt.plot(mesu.Data[\"cube\"].wavelength, sample)\n",
    "        plt.title(f'Spectra of Point: {x}, {y}')\n",
    "        plt.xlabel('Wavelength (nm)')\n",
    "        plt.ylabel('Counts')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "            \n",
    "# Show the inital image\n",
    "slider.observe(on_value_change)\n",
    "x_val.observe(on_value_change)\n",
    "y_val.observe(on_value_change)\n",
    "neighborhood.observe(on_value_change)\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        widgets.HBox([\n",
    "            out,\n",
    "            out_spectra\n",
    "        ]),\n",
    "        widgets.HBox([\n",
    "            slider,\n",
    "            x_val,\n",
    "            y_val,\n",
    "            neighborhood\n",
    "        ])\n",
    "])\n",
    ")\n",
    "show_channel(slider.value)\n",
    "plot_spectra()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492274e1",
   "metadata": {},
   "source": [
    "This graphical user interface gives us a simple user interface to change through the image channels and highlight spectral of samples. Dragging the slider will update the selected image channel. The plot on the right shows the uncorrected spectral profile for the pixels contained in the green circle on the left. Try playing with the UI to explore some of your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ed6e2",
   "metadata": {},
   "source": [
    "### Color Space Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb1a4e8",
   "metadata": {},
   "source": [
    "We can also use the same GUI tools to visual a color representation of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "red = widgets.SelectionSlider(\n",
    "    options=mesu.Data[\"cube\"].wavelength,\n",
    "    value=mesu.Data[\"cube\"].wavelength[0],\n",
    "    description='Ch 1 (R):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True\n",
    ")\n",
    "green = widgets.SelectionSlider(\n",
    "    options=mesu.Data[\"cube\"].wavelength,\n",
    "    value=mesu.Data[\"cube\"].wavelength[1],\n",
    "    description='Ch 2 (G):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True\n",
    ")\n",
    "blue = widgets.SelectionSlider(\n",
    "    options=mesu.Data[\"cube\"].wavelength,\n",
    "    value=mesu.Data[\"cube\"].wavelength[2],\n",
    "    description='Ch 3 (B):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True\n",
    ")\n",
    "common_vis = widgets.RadioButtons(\n",
    "    options=['Off', 'RGB', 'CIR'],\n",
    "    description='Common Visualizations:',\n",
    "    disabled=False\n",
    ")\n",
    "def create_rgb(_: traitlets.utils.bunch.Bunch) -> None:\n",
    "    red_channel = data[:,:,mesu.Data[\"cube\"].wavelength.index(red.value)]\n",
    "    blue_channel = data[:,:,mesu.Data[\"cube\"].wavelength.index(blue.value)]\n",
    "    green_channel = data[:,:,mesu.Data[\"cube\"].wavelength.index(green.value)]\n",
    "    with out_rgb:\n",
    "        clear_output(True)\n",
    "        rgb = np.dstack((red_channel, green_channel, blue_channel))\n",
    "        rgb_norm = cv2.normalize(rgb, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        plt.imshow(rgb_norm, extent=[0, data.shape[1], 0, data.shape[0]])\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.show()\n",
    "\n",
    "def set_bands(event: traitlets.utils.bunch.Bunch) -> None:\n",
    "    if event.get('name') == 'value':\n",
    "        # Set the slider values\n",
    "        if event.get('new') == 'CIR':\n",
    "            red.value = 842\n",
    "            green.value = 682\n",
    "            blue.value = 562\n",
    "        elif event.get('new') == 'RGB':\n",
    "            red.value = 682\n",
    "            green.value = 562\n",
    "            blue.value = 498\n",
    "        \n",
    "# Show the inital image\n",
    "out_rgb = widgets.Output()\n",
    "red.observe(create_rgb)\n",
    "blue.observe(create_rgb)\n",
    "green.observe(create_rgb)\n",
    "common_vis.observe(set_bands)\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        widgets.HBox([\n",
    "            out_rgb,\n",
    "            common_vis\n",
    "        ]),\n",
    "        widgets.HBox([\n",
    "            red,\n",
    "            green,\n",
    "            blue,\n",
    "        ])\n",
    "])\n",
    ")\n",
    "create_rgb(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d56b2d",
   "metadata": {},
   "source": [
    "### Reflectance Normalization and Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3472b2",
   "metadata": {},
   "source": [
    "Hyperspectral sensors have a wide dynamic range depending on the integraiton time and the amount of available illumination. For most classification algorithms, it is useful if we can have our values scaled between 0 and 1. To achieve this, we apply reflectance calibraiton, which takes our data and compares it to the absolute maximum and minimum possible signals given the current conditions. Behind the scenes, the Cuvis SDK applies the following equation to the datacube.\n",
    "\n",
    "$$\\text{signal}_{\\text{cal}} = \\frac{\\text{signal}_{\\text{raw}}-\\text{dark}}{\\text{white}-\\text{dark}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd723b36",
   "metadata": {},
   "source": [
    "#### Load white reflectance cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser(fc.selected_path) # Note, this should be in the white_000 directory\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319bb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_ref = cuvis.Measurement(fc.selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683adefa",
   "metadata": {},
   "source": [
    "#### Load dark reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c5d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser(fc.selected_path) # dark_000 folder\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3abbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_ref = cuvis.Measurement(fc.selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45413a",
   "metadata": {},
   "source": [
    "### Load distance reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db51c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser(fc.selected_path) # Calibration folder\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = cuvis.Measurement(fc.selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d76047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "factoryDir = 'C:/Program Files/Cuvis/sdk/sample_data/set1/factory' # Sensor factory calibration directory\n",
    "calibration = cuvis.Calibration(calibdir=factoryDir) # Create the calibration directory\n",
    "processingContext = cuvis.ProcessingContext(calibration) # Create the processing context given the calibration\n",
    "processingContext.setReference(dark_ref, \"Dark\") # Load the dark reference\n",
    "processingContext.setReference(white_ref, \"White\") # Load the white reference\n",
    "processingContext.setReference(distance, \"Distance\")\n",
    "\n",
    "modes = [\"Raw\",\n",
    "         \"DarkSubtract\",\n",
    "         \"Reflectance\",\n",
    "         ]\n",
    "procArgs = cuvis.CubertProcessingArgs()\n",
    "outputCubes = {}\n",
    "for mode in modes:\n",
    "    procArgs.ProcessingMode = mode\n",
    "    if processingContext.isCapable(mesu, procArgs):\n",
    "        print(\"processing to mode {}...\".format(mode))\n",
    "        processingContext.setProcessingArgs(procArgs)\n",
    "        outputCubes[mode] = deepcopy(processingContext.apply(mesu))\n",
    "    else:\n",
    "        print(\"Cannot process to {} mode!\".format(mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205b6be",
   "metadata": {},
   "source": [
    "Now that our cube is normalized, let's view a histogram of the points. Moreover, let's compare a classical calculation to Cuvis' results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbbe766",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputCubes['Reflectance'].Data['cube'].array\n",
    "counts, bins = np.histogram(outputCubes['Reflectance'].Data['cube'].array.flatten())\n",
    "plt.stairs(counts, bins)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Cuvis Calculated Reflectance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b173df",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cube = (data-dark_ref.Data['cube'].array) / (white_ref.Data['cube'].array-dark_ref.Data['cube'].array)\n",
    "counts, bins = np.histogram(output_cube.flatten())\n",
    "plt.stairs(counts, bins)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Manually Calculated Reflectance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57593c63",
   "metadata": {},
   "source": [
    "### PCA and explained total variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad74ce0",
   "metadata": {},
   "source": [
    "Hyperspectral data is often considered \"big data\", which makes it a challenging domain for real-time data processing pipelines. One thing that often helps simplify data analysis is to perform a dimensionality reduction technique to reduce the number of spectral components used to represent the spectrum. Here we will use Principal Components Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b97f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(output_cube.reshape(-1, output_cube.shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60ba50",
   "metadata": {},
   "source": [
    "PCA applies a linear reprojection to the original feature space, which allows an interpretation of the components by the amount of variation explained in the data. Below, we will plot the total explained variance as a function of the number of components in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7289aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(output_cube.shape[2]),np.cumsum(pca.explained_variance_ratio_)*100)\n",
    "plt.xlabel('Number of Components (Spectral Bands)')\n",
    "plt.ylabel('Explained Variance (%)')\n",
    "plt.title('Principal Component Analysis on HyperCube')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9c5b2",
   "metadata": {},
   "source": [
    "As you can clearly see from the results above, <10 components should be needed to explain almost the entirety of the variation in the dataset. Other dimensionality techniques, like Singular Value Decomposition, Minimum Noise Fraction, Factor Analysis, and Nonnegative Matrix Factorization can be subsitituted here, and make for some thrilling mathematical reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3e2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cube_reduced = pca.transform(output_cube.reshape(-1, output_cube.shape[-1]))\n",
    "reduced_cube = output_cube_reduced.reshape(output_cube.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266cabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "components_to_keep = 10 # Pick the total number of components to use\n",
    "reduced_cube_final = reduced_cube[:,:,:components_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12863c9e",
   "metadata": {},
   "source": [
    "### K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c789f",
   "metadata": {},
   "source": [
    "As a practical demonstration of the CUVIS processing pipeline, we will now apply an _unsupervised_ machine learning algorithm, K-Means clustering, to our PCA transformed datacube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55fddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(\n",
    "    init=\"random\",\n",
    "    n_clusters=4, # This value is up to you! How many classes do you think should be in the image?\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "flattened_data = reduced_cube_final.reshape(-1, reduced_cube_final.shape[-1])\n",
    "kmeans.fit(flattened_data)\n",
    "preds = kmeans.predict(flattened_data)\n",
    "plt.imshow(preds.reshape((reduced_cube.shape[0],reduced_cube.shape[1])))\n",
    "plt.title('PCA K-Means Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc60ca",
   "metadata": {},
   "source": [
    "Now let's compare this to the results if we use the entire data cube without dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230da897",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(\n",
    "    init=\"random\",\n",
    "    n_clusters=4, # This value is up to you! How many classes do you think should be in the image?\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "flattened_data = output_cube.reshape(-1, output_cube.shape[-1])\n",
    "kmeans.fit(flattened_data)\n",
    "preds = kmeans.predict(flattened_data)\n",
    "plt.imshow(preds.reshape((output_cube.shape[0], output_cube.shape[1])))\n",
    "plt.title('Full Data K-Means Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a809e",
   "metadata": {},
   "source": [
    "Note the colors in the image might change between images, but the shape contours should converge to the same result consistently. As you can see from the results, a reduced number of components is sufficient to differentiate the plant from the backgorund. Try rerunning these calculations with a different number of clusters, and then compare the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e061cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "453d35c7e9cf155cd69c9bbf753ab7d3c0ab97078802c583bb2c23987c353771"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
